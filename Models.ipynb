{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsFnBxIYQ8-z",
        "colab_type": "text"
      },
      "source": [
        "# Оценим данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tp3euvBvDQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b3f47ed8-27e7-4544-b55b-c1993e39e432"
      },
      "source": [
        "!unzip /content/data_task.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/data_task.zip\n",
            "  inflating: data_task/col_name.txt  \n",
            "  inflating: data_task/test_p.csv    \n",
            "  inflating: data_task/train_p.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGeqdtkBRD-L",
        "colab_type": "text"
      },
      "source": [
        "Библиотеки для работы с данными."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjUOl5KgvrWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gAeSrSivevU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/content/data_task/test_p.csv')\n",
        "train = pd.read_csv('/content/data_task/train_p.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOesJBcDRH4i",
        "colab_type": "text"
      },
      "source": [
        "Примерно 88-90% от изначального объема данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ResDxNU6v6ZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa94462b-d1e8-4fa4-e38f-5a8f3a92a9b0"
      },
      "source": [
        "train.shape , test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((964, 1440), (164, 1439))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhNQnWd0RPxt",
        "colab_type": "text"
      },
      "source": [
        "Разделим данные на параметры и предсказание."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRiupFUMyigN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.drop(columns=['sample_id','y'])\n",
        "y_train = train['y']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJU0TS5LRZIE",
        "colab_type": "text"
      },
      "source": [
        "Подготовим тренировочные данные, для предсказания. И отдельно колонка с названием. \n",
        "\n",
        "P.S. Индексы сохраняются."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjl7Xi8qysSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = test.drop(columns=['sample_id'])\n",
        "X_name = test['sample_id']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATnq9E3PzI8B",
        "colab_type": "text"
      },
      "source": [
        "Набор не идеально сбалансирован, однако разница в распределении классов не столь существенна, чтобы применять решения, предназначенные для сильно несбалансированных случаев."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rundni2hzDiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "0b5c37a8-6666-407e-84ce-3a04bb62bd89"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(train['y'],label=\"Sum\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkX8y6waRPIk",
        "colab_type": "text"
      },
      "source": [
        "Чтобы повысить точность, стандартизируем данные для baseline моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv6CHHUqQaU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def standardize(train, test):\n",
        "    mean = np.mean(train, axis=0)\n",
        "    std = np.std(train, axis=0)+0.000001\n",
        "\n",
        "    X_train = (train - mean) / std\n",
        "    X_test = (test - mean) /std\n",
        "    return X_train, X_test"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H25AhtxxRTUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = standardize(X_train, X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkz-hOfnanKI",
        "colab_type": "text"
      },
      "source": [
        "Обучаем модель. Keras Sequential API.\n",
        "\n",
        "P.S. Помимо Sequential, есть и Functional API, но принципиального отличия между способами нет.\n",
        "Класс Model (и унаследованный от него Sequential) имеет удобный интерфейс, позволяющий посмотреть, какие слои входят в модель — model.layers, входы — model.inputs, и выходы — model.outputs.\n",
        "\n",
        "\n",
        "Также очень удобный метод отображения и сохранения модели — model.to_yaml."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xmUvRy7bOr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e870b6b4-6637-4c13-b3f5-544be3aae246"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDsqKgy9b1nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9oAoxR4SSVx",
        "colab_type": "text"
      },
      "source": [
        "Разделим тренировочный датасет на валидационные данные в соотношении 15%, объем данный не большой. Для чего это нужно. Мы передаем валидационные данные для мониторинга потерь и метрик на этих данных в конце каждой эпохи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYmjy3TEGtjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Зарезервируем 15% примеров для валидации\n",
        "X_val = X_train[-145:]\n",
        "y_val = y_train[-145:]\n",
        "X = X_train[:-145]\n",
        "Y = y_train[:-145]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaJ0XFtuSqMo",
        "colab_type": "text"
      },
      "source": [
        "Полная метрика, для ROC-AUC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDBwn_FvvAwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUBnLCKFgZWu",
        "colab_type": "text"
      },
      "source": [
        "# Выбор гиперпараметров"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3vk_CRrS0ib",
        "colab_type": "text"
      },
      "source": [
        "**Обучаем модель. Подробнее:**\n",
        "\n",
        "Для compile в качестве loss (минимизируемая функция потерь), берем 'binary_crossentropy', т.к. предсказываем только одно значение и это соотвествует стандартной сигнатуре (нужные кастомные метрики, могут быть вычислены из y_true, y_pred). По этой причине, у нас стоит Dense(1,...,activation='sigmoid'), если бы у нас было бы больше чем один класс для предсказания, например датасет MNIST, тогда разумеется брали 'categorical_crossentropy' с Density(10,...,activation='softmax').\n",
        "\n",
        "Кстати, вместо 'softmax', взяли 'sigmoid'. Сигмовидные функции используются в машинном обучении для логистической регрессии и базовых реализаций нейронной сети и являются вводными единицами активации. Но для продвинутых сигмаидных функций нейронной сети они не предпочтительны из-за различных недостатков. Хотя сигмовидная функция и ее производная просты и помогают сократить время, необходимое для создания моделей, существует существенный недостаток потери информации из-за короткого диапазона производной.\n",
        "\n",
        "Следовательно, чем больше слоев в нашей нейронной сети или чем глубже наша нейронная сеть, тем больше информации сжимается и теряется на каждом уровне, что усиливается и приводит к значительной потере данных в целом. По причине, того что это бинарная класификация, сжатие информации не страшно, т.к. один нейроный слой для сигмовидной функции.\n",
        "\n",
        "Большинство приложений глубокого обучения в настоящее время используют ReLU вместо функций логистической активации, что мы и сделали при строительстве нейронных сетей. ReLU не лишены каких-либо недостатков, некоторые из них заключаются в том, что ReLU не центрируется на ноль и не дифференцируется в нуле, но дифференцируется в любом другом месте. По этой причине, делаем сглаживние сигмовидной функцией. \n",
        "\n",
        "![Sigmoid Vs ReLU](https://miro.medium.com/max/700/1*29VH_NiSdoLJ1jUMLrURCA.png)\n",
        "\n",
        "Некоторые проблемы ReLU с нейроными сетями, могут быть решены Leaky ReLU. \n",
        "\n",
        "И основной вопрос, почему взяли 'sigmoid', а не 'softmax' для обучения на энтропии потерь. \n",
        "\n",
        "Потому, что 'softmax' используется для мультиклассификации в модели логистической регрессии, тогда как 'sigmoid' используется для двоичной классификации в модели логистической регрессии, сумма вероятностей равна единице для 'softmax'. А значит, 'softmax' не проявит себя в двоичной классификации, но затрить больше времени. \n",
        "\n",
        "**Что насчет оптимизатора?**\n",
        "Обновить параметры выходного слоя довольно просто, но чтобы добраться до параметров слоёв за ним, приходится проходить через нелинейности, производные от которых вносят свой вклад. Явно расписанные формулы для обновления весов где-нибдуь в середине сети выглядят страшненько, ведь каждый нейрон зависит ото всех нейронов, с которымии он связан, а те — ото всех нейронов, с которыми связаны они, и так далее. Оптимизаторы нужны, чтобы решить ряд проблем, например застревание в локальных минимумах или седловых точках, сложный ландшафт целевой функции, маленькая скорость обучения, итд. Идея потимизатора, накапливать импульсы, т.е. если мы некоторое время движемся в определённом направлении, то, вероятно, нам следует туда двигаться некоторое время и в будущем. Для этого нужно уметь обращаться к недавней истории изменений каждого параметра.\n",
        "\n",
        "Оптимизатор — один из двух аргументов, необходимых для компиляции модели Keras. Его можно настроить, или взять уже с параметрами. \n",
        "Оптимизатор SGD (стохастический оптимизатор градиентного спуска), RMSProp, Adagrad, Adadelta, Adam, Adamax, Nadam.\n",
        "\n",
        "Выбрали для обученя модели, оптимизатор Adam, который по сути являестя RMSprop с импульсом. Параметры по умолчанию, keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False). **Он сочетает в себе и идею накопления движения и идею более слабого обновления весов для типичных признаков. **\n",
        "\n",
        "learning_rate: float >= 0. Скорость обучения.\n",
        "beta_1: float, 0 < beta < 1. Обычно близко к 1.\n",
        "beta_2: float, 0 < beta < 1. Обычно близко к 1.\n",
        "\n",
        "Adam отличается тем, что мы накапливаем значения градиента. Кроме того, мы хотим знать, как часто градиент изменяется.\n",
        "\n",
        "Выбор оптимизатора, производился для простых датасетов, на основе вывода статьи. Я бы предложил держать качестве «золотого молотка» Adam, так как он выдаёт наилучшие результаты при минимальном подгоне параметров. Когда сеть уже более-менее отлажена, попробуйте метод Нестерова с разными параметрами.\n",
        "\n",
        "![Оптимизатор для простых датасетов](https://hsto.org/files/270/4f7/4f5/2704f74f52764a2d83f519c16dd3bc9c.png)\n",
        "\n",
        "Выбор гиперпараметров производился, на основе графика, и сравнения точности моделей. Основной критерий, времени экномится больше, чем увиличивается AUC от обучения.\n",
        "\n",
        "Выбирались параметры, колличество нейроных сетей, эпох обучения, и количество образцов на обновлении градиента, теперь подробнее.\n",
        "\n",
        "batch_size: Целое или нет. Количество образцов на обновление градиента. Если не указано, то по умолчанию параметр batch_size будет равен 32. Не указывайте размер переменной batch_size, если ваши данные представлены в виде символических тензоров, генераторов или экземпляров последовательности (поскольку они генерируют партии).\n",
        "\n",
        "Размер партии значительно влияет на обучение. Когда вы помещаете пакет в свою сеть, происходит то, что вы усредняете градиенты. Концепция заключается в том, что если размер вашей партии достаточно велик, это обеспечит достаточно стабильную оценку того, каким будет градиент полного набора данных. Взяв образцы из вашего набора данных, вы оцените градиент при значительном снижении вычислительных затрат. Чем ниже вы идете, тем менее точной будет ваша оценка, однако в некоторых случаях эти шумовые градиенты могут фактически помочь избежать локальных минимумов. Когда оно слишком низкое, вес вашей сети может просто перепрыгнуть, если ваши данные шумят, и они могут быть неспособны к обучению или они сходятся очень медленно, что отрицательно влияет на общее время вычислений\n",
        "\n",
        "Размер batch_size в среднем влияет только на скорость вашего обучения, а не на качество обучения. Я попытался получить большой размер batch_size, который по-прежнему умещается в памяти графического процессора, чтобы получить максимально возможную скорость.\n",
        "\n",
        "epochs: Целое. Количество эпох для обучения модели. Эпоха — это итерация по всем предоставленным данным x и y. Обратите внимание, что в сочетании с initial_epoch, эпохи должны пониматься как «конечная эпоха». Модель не тренируется для ряда итераций, заданных эпохами, а только до тех пор, пока не будет достигнута эпоха индексов.\n",
        "Подбор производился опираясь на значения результатов статьи и своих сравнений.\n",
        "\n",
        "Колличество нейроных слоев. Dense просто обычный плотно связанный слой NN. Dense реализует операцию: output = activation(dot(input, kernel) + bias), где активация — это функция активации по элементам, переданная в качестве аргумента активации, кернел — это матрица весов, созданная слоем, а смещение — это вектор смещения, созданный слоем (применимо только в случае, если use_bias — True).\n",
        "\n",
        "Замечание: если вход в слой имеет ранг больше 2, то он сглаживается перед исходным точечным продуктом с кернелом.\n",
        "\n",
        "Выбор units: положительное целое число, размерность выходного пространства, для Dense. Нейронные сети - это, в основном, умножение матриц, падение, о котором вы говорите в первой части, связано не с функцией активации, а только с природой умножения матриц:\n",
        "\n",
        "Просто говоря, считаем так: input * weights = output. Подбираем этот параметр, при уже зафиксированных значениях epoch, bach_size. Вывод делался по значениям AUC.\n",
        "\n",
        "Источники: \n",
        "\n",
        "[1] Методы оптимизации нейронных сетей https://habr.com/ru/post/318970/\n",
        "\n",
        "[2] Оптимизаторы https://ru-keras.com/optimizer/\n",
        "\n",
        "[3] Activation function https://medium.com/@himanshuxd/\n",
        "activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e\n",
        "\n",
        "[4] Методы последовательной модели https://ru-keras.com/sequential/\n",
        "\n",
        "[5] Основные слои https://ru-keras.com/core-layers/\n",
        "\n",
        "[6] FAQ https://ru-keras.com/keras-faq/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alcw79YfgdYL",
        "colab_type": "text"
      },
      "source": [
        "# Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW9yxegRUDg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e93b811-5b38-433e-c466-fb9cc2144c70"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, init='uniform', activation='relu'))\n",
        "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[METRICS])\n",
        "history = model.fit(X.values, Y.values, epochs=28, batch_size=128, \n",
        "          validation_data=(X_val.values, y_val.values))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 819 samples, validate on 145 samples\n",
            "Epoch 1/28\n",
            "819/819 [==============================] - 0s 397us/step - loss: 0.6093 - tp: 197.8571 - fp: 85.4286 - tn: 115.2857 - fn: 102.4286 - accuracy: 0.5966 - precision: 0.6767 - recall: 0.6263 - auc: 0.6396 - val_loss: 0.5307 - val_tp: 422.0000 - val_fp: 144.0000 - val_tn: 211.5000 - val_fn: 178.0000 - val_accuracy: 0.6630 - val_precision: 0.7456 - val_recall: 0.7033 - val_auc: 0.7247\n",
            "Epoch 2/28\n",
            "819/819 [==============================] - 0s 62us/step - loss: 0.4892 - tp: 683.1429 - fp: 218.8571 - tn: 337.4286 - fn: 225.5714 - accuracy: 0.6947 - precision: 0.7571 - recall: 0.7491 - auc: 0.7630 - val_loss: 0.4908 - val_tp: 927.0000 - val_fp: 274.5000 - val_tn: 439.0000 - val_fn: 279.0000 - val_accuracy: 0.7116 - val_precision: 0.7715 - val_recall: 0.7687 - val_auc: 0.7795\n",
            "Epoch 3/28\n",
            "819/819 [==============================] - 0s 61us/step - loss: 0.4376 - tp: 1191.5714 - fp: 337.4286 - tn: 579.1429 - fn: 320.8571 - accuracy: 0.7284 - precision: 0.7791 - recall: 0.7872 - auc: 0.7991 - val_loss: 0.4797 - val_tp: 1441.5000 - val_fp: 384.0000 - val_tn: 687.5000 - val_fn: 370.5000 - val_accuracy: 0.7383 - val_precision: 0.7896 - val_recall: 0.7955 - val_auc: 0.8092\n",
            "Epoch 4/28\n",
            "819/819 [==============================] - 0s 66us/step - loss: 0.4029 - tp: 1710.7142 - fp: 442.7143 - tn: 832.4286 - fn: 407.1429 - accuracy: 0.7492 - precision: 0.7943 - recall: 0.8074 - auc: 0.8220 - val_loss: 0.4627 - val_tp: 1966.0000 - val_fp: 486.0000 - val_tn: 943.5000 - val_fn: 452.0000 - val_accuracy: 0.7562 - val_precision: 0.8018 - val_recall: 0.8131 - val_auc: 0.8302\n",
            "Epoch 5/28\n",
            "819/819 [==============================] - 0s 56us/step - loss: 0.3769 - tp: 2241.4285 - fp: 546.5714 - tn: 1088.1428 - fn: 480.8571 - accuracy: 0.7640 - precision: 0.8038 - recall: 0.8231 - auc: 0.8399 - val_loss: 0.4529 - val_tp: 2501.0000 - val_fp: 588.0000 - val_tn: 1199.5000 - val_fn: 523.0000 - val_accuracy: 0.7691 - val_precision: 0.8096 - val_recall: 0.8270 - val_auc: 0.8450\n",
            "Epoch 6/28\n",
            "819/819 [==============================] - 0s 61us/step - loss: 0.3524 - tp: 2785.1428 - fp: 635.2857 - tn: 1347.4286 - fn: 553.1429 - accuracy: 0.7766 - precision: 0.8143 - recall: 0.8342 - auc: 0.8538 - val_loss: 0.4937 - val_tp: 3036.5000 - val_fp: 682.5000 - val_tn: 1463.0000 - val_fn: 593.5000 - val_accuracy: 0.7791 - val_precision: 0.8165 - val_recall: 0.8365 - val_auc: 0.8564\n",
            "Epoch 7/28\n",
            "819/819 [==============================] - 0s 54us/step - loss: 0.3255 - tp: 3314.2856 - fp: 733.1429 - tn: 1611.1428 - fn: 626.4286 - accuracy: 0.7836 - precision: 0.8188 - recall: 0.8410 - auc: 0.8632 - val_loss: 0.4911 - val_tp: 3568.0000 - val_fp: 770.0000 - val_tn: 1733.5000 - val_fn: 668.0000 - val_accuracy: 0.7866 - val_precision: 0.8225 - val_recall: 0.8423 - val_auc: 0.8666\n",
            "Epoch 8/28\n",
            "819/819 [==============================] - 0s 61us/step - loss: 0.3054 - tp: 3849.7144 - fp: 817.0000 - tn: 1886.0000 - fn: 696.2857 - accuracy: 0.7912 - precision: 0.8249 - recall: 0.8468 - auc: 0.8730 - val_loss: 0.5116 - val_tp: 4104.5000 - val_fp: 854.5000 - val_tn: 2007.0000 - val_fn: 737.5000 - val_accuracy: 0.7933 - val_precision: 0.8277 - val_recall: 0.8477 - val_auc: 0.8753\n",
            "Epoch 9/28\n",
            "819/819 [==============================] - 0s 62us/step - loss: 0.2890 - tp: 4383.5713 - fp: 901.7143 - tn: 2167.7144 - fn: 760.0000 - accuracy: 0.7976 - precision: 0.8294 - recall: 0.8522 - auc: 0.8811 - val_loss: 0.4980 - val_tp: 4652.0000 - val_fp: 940.0000 - val_tn: 2279.5000 - val_fn: 796.0000 - val_accuracy: 0.7997 - val_precision: 0.8319 - val_recall: 0.8539 - val_auc: 0.8829\n",
            "Epoch 10/28\n",
            "819/819 [==============================] - 0s 57us/step - loss: 0.2694 - tp: 4941.7144 - fp: 984.7143 - tn: 2435.2856 - fn: 815.2857 - accuracy: 0.8038 - precision: 0.8338 - recall: 0.8583 - auc: 0.8877 - val_loss: 0.5037 - val_tp: 5210.0000 - val_fp: 1024.0000 - val_tn: 2553.5000 - val_fn: 844.0000 - val_accuracy: 0.8061 - val_precision: 0.8357 - val_recall: 0.8606 - val_auc: 0.8898\n",
            "Epoch 11/28\n",
            "819/819 [==============================] - 0s 59us/step - loss: 0.2526 - tp: 5494.8569 - fp: 1061.8572 - tn: 2716.1428 - fn: 868.1429 - accuracy: 0.8096 - precision: 0.8380 - recall: 0.8635 - auc: 0.8944 - val_loss: 0.5385 - val_tp: 5751.5000 - val_fp: 1093.0000 - val_tn: 2842.5000 - val_fn: 908.5000 - val_accuracy: 0.8111 - val_precision: 0.8403 - val_recall: 0.8636 - val_auc: 0.8960\n",
            "Epoch 12/28\n",
            "819/819 [==============================] - 0s 71us/step - loss: 0.2397 - tp: 6039.1431 - fp: 1124.8572 - tn: 3008.7144 - fn: 932.2857 - accuracy: 0.8147 - precision: 0.8430 - recall: 0.8662 - auc: 0.8999 - val_loss: 0.5403 - val_tp: 6302.5000 - val_fp: 1156.0000 - val_tn: 3137.5000 - val_fn: 963.5000 - val_accuracy: 0.8166 - val_precision: 0.8450 - val_recall: 0.8674 - val_auc: 0.9016\n",
            "Epoch 13/28\n",
            "819/819 [==============================] - 0s 75us/step - loss: 0.2248 - tp: 6587.2856 - fp: 1186.8572 - tn: 3313.0000 - fn: 981.8571 - accuracy: 0.8203 - precision: 0.8473 - recall: 0.8703 - auc: 0.9055 - val_loss: 0.5408 - val_tp: 6855.0000 - val_fp: 1213.0000 - val_tn: 3438.5000 - val_fn: 1017.0000 - val_accuracy: 0.8219 - val_precision: 0.8497 - val_recall: 0.8708 - val_auc: 0.9068\n",
            "Epoch 14/28\n",
            "819/819 [==============================] - 0s 63us/step - loss: 0.2129 - tp: 7148.2856 - fp: 1244.2858 - tn: 3607.5715 - fn: 1032.8572 - accuracy: 0.8253 - precision: 0.8517 - recall: 0.8737 - auc: 0.9102 - val_loss: 0.5641 - val_tp: 7410.0000 - val_fp: 1271.0000 - val_tn: 3738.5000 - val_fn: 1068.0000 - val_accuracy: 0.8266 - val_precision: 0.8536 - val_recall: 0.8740 - val_auc: 0.9113\n",
            "Epoch 15/28\n",
            "819/819 [==============================] - 0s 63us/step - loss: 0.1976 - tp: 7700.0000 - fp: 1297.0000 - tn: 3917.4285 - fn: 1082.5714 - accuracy: 0.8300 - precision: 0.8558 - recall: 0.8767 - auc: 0.9146 - val_loss: 0.5683 - val_tp: 7968.0000 - val_fp: 1321.0000 - val_tn: 4046.5000 - val_fn: 1116.0000 - val_accuracy: 0.8314 - val_precision: 0.8578 - val_recall: 0.8771 - val_auc: 0.9157\n",
            "Epoch 16/28\n",
            "819/819 [==============================] - 0s 64us/step - loss: 0.1863 - tp: 8265.8574 - fp: 1347.0000 - tn: 4217.4287 - fn: 1130.7142 - accuracy: 0.8344 - precision: 0.8599 - recall: 0.8796 - auc: 0.9186 - val_loss: 0.5949 - val_tp: 8529.5000 - val_fp: 1370.0000 - val_tn: 4355.5000 - val_fn: 1160.5000 - val_accuracy: 0.8358 - val_precision: 0.8616 - val_recall: 0.8802 - val_auc: 0.9196\n",
            "Epoch 17/28\n",
            "819/819 [==============================] - 0s 65us/step - loss: 0.1760 - tp: 8822.0000 - fp: 1392.7142 - tn: 4537.0000 - fn: 1173.2858 - accuracy: 0.8388 - precision: 0.8636 - recall: 0.8826 - auc: 0.9223 - val_loss: 0.5795 - val_tp: 9094.0000 - val_fp: 1412.0000 - val_tn: 4671.5000 - val_fn: 1202.0000 - val_accuracy: 0.8404 - val_precision: 0.8656 - val_recall: 0.8833 - val_auc: 0.9232\n",
            "Epoch 18/28\n",
            "819/819 [==============================] - 0s 65us/step - loss: 0.1607 - tp: 9390.7139 - fp: 1428.2858 - tn: 4858.2856 - fn: 1211.7142 - accuracy: 0.8437 - precision: 0.8680 - recall: 0.8857 - auc: 0.9259 - val_loss: 0.5864 - val_tp: 9660.5000 - val_fp: 1447.0000 - val_tn: 4994.5000 - val_fn: 1241.5000 - val_accuracy: 0.8450 - val_precision: 0.8697 - val_recall: 0.8861 - val_auc: 0.9267\n",
            "Epoch 19/28\n",
            "819/819 [==============================] - 0s 68us/step - loss: 0.1506 - tp: 9954.0000 - fp: 1461.1428 - tn: 5187.0000 - fn: 1250.8572 - accuracy: 0.8481 - precision: 0.8720 - recall: 0.8884 - auc: 0.9293 - val_loss: 0.5959 - val_tp: 10230.5000 - val_fp: 1476.0000 - val_tn: 5323.5000 - val_fn: 1277.5000 - val_accuracy: 0.8496 - val_precision: 0.8739 - val_recall: 0.8890 - val_auc: 0.9300\n",
            "Epoch 20/28\n",
            "819/819 [==============================] - 0s 64us/step - loss: 0.1416 - tp: 10519.2861 - fp: 1488.2858 - tn: 5523.0000 - fn: 1286.4286 - accuracy: 0.8525 - precision: 0.8760 - recall: 0.8910 - auc: 0.9324 - val_loss: 0.6142 - val_tp: 10802.0000 - val_fp: 1503.0000 - val_tn: 5654.5000 - val_fn: 1312.0000 - val_accuracy: 0.8539 - val_precision: 0.8779 - val_recall: 0.8917 - val_auc: 0.9330\n",
            "Epoch 21/28\n",
            "819/819 [==============================] - 0s 64us/step - loss: 0.1304 - tp: 11098.4287 - fp: 1516.7142 - tn: 5849.2856 - fn: 1316.5714 - accuracy: 0.8568 - precision: 0.8798 - recall: 0.8939 - auc: 0.9352 - val_loss: 0.6281 - val_tp: 11380.5000 - val_fp: 1531.0000 - val_tn: 5984.5000 - val_fn: 1339.5000 - val_accuracy: 0.8581 - val_precision: 0.8814 - val_recall: 0.8947 - val_auc: 0.9358\n",
            "Epoch 22/28\n",
            "819/819 [==============================] - 0s 68us/step - loss: 0.1219 - tp: 11677.2861 - fp: 1542.1428 - tn: 6180.0000 - fn: 1345.5714 - accuracy: 0.8608 - precision: 0.8833 - recall: 0.8967 - auc: 0.9379 - val_loss: 0.6574 - val_tp: 11955.5000 - val_fp: 1557.0000 - val_tn: 6316.5000 - val_fn: 1370.5000 - val_accuracy: 0.8619 - val_precision: 0.8848 - val_recall: 0.8972 - val_auc: 0.9384\n",
            "Epoch 23/28\n",
            "819/819 [==============================] - 0s 61us/step - loss: 0.1130 - tp: 12256.5713 - fp: 1567.5714 - tn: 6507.1431 - fn: 1377.7142 - accuracy: 0.8643 - precision: 0.8866 - recall: 0.8989 - auc: 0.9403 - val_loss: 0.6763 - val_tp: 12528.5000 - val_fp: 1580.0000 - val_tn: 6651.5000 - val_fn: 1403.5000 - val_accuracy: 0.8654 - val_precision: 0.8880 - val_recall: 0.8993 - val_auc: 0.9407\n",
            "Epoch 24/28\n",
            "819/819 [==============================] - 0s 64us/step - loss: 0.1077 - tp: 12832.4287 - fp: 1589.5714 - tn: 6842.2856 - fn: 1408.7142 - accuracy: 0.8677 - precision: 0.8898 - recall: 0.9011 - auc: 0.9426 - val_loss: 0.6589 - val_tp: 13106.0000 - val_fp: 1605.0000 - val_tn: 6984.5000 - val_fn: 1432.0000 - val_accuracy: 0.8687 - val_precision: 0.8909 - val_recall: 0.9015 - val_auc: 0.9430\n",
            "Epoch 25/28\n",
            "819/819 [==============================] - 0s 67us/step - loss: 0.1025 - tp: 13405.0000 - fp: 1610.5714 - tn: 7182.2856 - fn: 1439.1428 - accuracy: 0.8710 - precision: 0.8927 - recall: 0.9030 - auc: 0.9447 - val_loss: 0.7063 - val_tp: 13679.5000 - val_fp: 1620.0000 - val_tn: 7327.5000 - val_fn: 1464.5000 - val_accuracy: 0.8720 - val_precision: 0.8941 - val_recall: 0.9033 - val_auc: 0.9450\n",
            "Epoch 26/28\n",
            "819/819 [==============================] - 0s 69us/step - loss: 0.0916 - tp: 13982.7139 - fp: 1625.7142 - tn: 7525.0000 - fn: 1467.5714 - accuracy: 0.8743 - precision: 0.8958 - recall: 0.9050 - auc: 0.9466 - val_loss: 0.6798 - val_tp: 14261.0000 - val_fp: 1637.0000 - val_tn: 7668.5000 - val_fn: 1489.0000 - val_accuracy: 0.8752 - val_precision: 0.8970 - val_recall: 0.9055 - val_auc: 0.9470\n",
            "Epoch 27/28\n",
            "819/819 [==============================] - 0s 69us/step - loss: 0.0863 - tp: 14565.8574 - fp: 1641.8572 - tn: 7866.8569 - fn: 1490.4286 - accuracy: 0.8775 - precision: 0.8987 - recall: 0.9072 - auc: 0.9486 - val_loss: 0.7461 - val_tp: 14842.5000 - val_fp: 1654.0000 - val_tn: 8009.5000 - val_fn: 1513.5000 - val_accuracy: 0.8783 - val_precision: 0.8997 - val_recall: 0.9075 - val_auc: 0.9487\n",
            "Epoch 28/28\n",
            "819/819 [==============================] - 0s 67us/step - loss: 0.0867 - tp: 15142.7139 - fp: 1660.1428 - tn: 8208.0000 - fn: 1518.1428 - accuracy: 0.8802 - precision: 0.9012 - recall: 0.9089 - auc: 0.9501 - val_loss: 0.7227 - val_tp: 15421.0000 - val_fp: 1671.0000 - val_tn: 8350.5000 - val_fn: 1541.0000 - val_accuracy: 0.8810 - val_precision: 0.9022 - val_recall: 0.9091 - val_auc: 0.9503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGv8mVN3wuxI",
        "colab_type": "text"
      },
      "source": [
        "Сохраним модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbpGNw4IwUNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('keras_model.h5')    # Создает файл HDF5 ‘my_model.h5’\n",
        "\n",
        "#del model    # Удаляет существующую модель\n",
        "\n",
        "#model = load_model('my_model.h5')    # Возвращает скомпилированную модель"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DidJL5s1mK6l",
        "colab_type": "text"
      },
      "source": [
        "Увеличия epoch и units, величит значение AUC. Например, при **epoch = 50**, и тем же колличеством слоев, можно поднять AUC с **95% до 97.5%**, а увеличинем нейроного слоя **units до 128**, можно добиться **AUC 98.5%**. Тем не менее, нашего значения AUC достаточно, для класификации и совпадание с результатами из задания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awBiVwefIX3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "66961b1f-dd38-4a59-b983-d3e26605b447"
      },
      "source": [
        "print('\\nhistory dict:', history.history)    # Для оценки AUC и выбора параметров. "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "history dict: {'val_loss': [0.5306934954791234, 0.4908246085561555, 0.4796790961561532, 0.4626501173808657, 0.4529381858891454, 0.49372588211092455, 0.49111901727215995, 0.5116221980801944, 0.49801892083266686, 0.5036941772904889, 0.5384767980411135, 0.5402786633064007, 0.540773147961189, 0.5640846807381202, 0.5683454357344528, 0.5949245736516755, 0.5794739651268926, 0.5863640180949508, 0.5958913747606607, 0.6141998880896075, 0.6280758206186623, 0.6573829644712909, 0.6763245691513193, 0.6588934236559375, 0.7062640210677837, 0.679819944809223, 0.7460975741517955, 0.7227400185733006], 'val_tp': [422.0, 927.0, 1441.5, 1966.0, 2501.0, 3036.5, 3568.0, 4104.5, 4652.0, 5210.0, 5751.5, 6302.5, 6855.0, 7410.0, 7968.0, 8529.5, 9094.0, 9660.5, 10230.5, 10802.0, 11380.5, 11955.5, 12528.5, 13106.0, 13679.5, 14261.0, 14842.5, 15421.0], 'val_fp': [144.0, 274.5, 384.0, 486.0, 588.0, 682.5, 770.0, 854.5, 940.0, 1024.0, 1093.0, 1156.0, 1213.0, 1271.0, 1321.0, 1370.0, 1412.0, 1447.0, 1476.0, 1503.0, 1531.0, 1557.0, 1580.0, 1605.0, 1620.0, 1637.0, 1654.0, 1671.0], 'val_tn': [211.5, 439.0, 687.5, 943.5, 1199.5, 1463.0, 1733.5, 2007.0, 2279.5, 2553.5, 2842.5, 3137.5, 3438.5, 3738.5, 4046.5, 4355.5, 4671.5, 4994.5, 5323.5, 5654.5, 5984.5, 6316.5, 6651.5, 6984.5, 7327.5, 7668.5, 8009.5, 8350.5], 'val_fn': [178.0, 279.0, 370.5, 452.0, 523.0, 593.5, 668.0, 737.5, 796.0, 844.0, 908.5, 963.5, 1017.0, 1068.0, 1116.0, 1160.5, 1202.0, 1241.5, 1277.5, 1312.0, 1339.5, 1370.5, 1403.5, 1432.0, 1464.5, 1489.0, 1513.5, 1541.0], 'val_accuracy': [0.6629956364631653, 0.7116414308547974, 0.7383370399475098, 0.7562041282653809, 0.7690941691398621, 0.7790665626525879, 0.7866307497024536, 0.7933405637741089, 0.7997114658355713, 0.8060529828071594, 0.8110990524291992, 0.8166443109512329, 0.8219347596168518, 0.8265801668167114, 0.8313669562339783, 0.835847020149231, 0.8404102325439453, 0.8449851274490356, 0.849597156047821, 0.8539294004440308, 0.8581453561782837, 0.8619071245193481, 0.8653867840766907, 0.8686844706535339, 0.8719673156738281, 0.875236988067627, 0.8782643675804138, 0.8809642791748047], 'val_precision': [0.7455731630325317, 0.7715326547622681, 0.7896447777748108, 0.8017932772636414, 0.8096464276313782, 0.816482663154602, 0.8224985003471375, 0.8276869058609009, 0.8319026827812195, 0.8357394933700562, 0.840309739112854, 0.8450090885162354, 0.8496529459953308, 0.8535882830619812, 0.8577888011932373, 0.8616092205047607, 0.8656005859375, 0.8697276711463928, 0.8739162087440491, 0.877854585647583, 0.8814235329627991, 0.8847733736038208, 0.8880107402801514, 0.8908979892730713, 0.8941141963005066, 0.8970310688018799, 0.8997362852096558, 0.9022349715232849], 'val_recall': [0.7033203840255737, 0.7686551213264465, 0.7955284714698792, 0.8130674958229065, 0.8270496129989624, 0.8365011811256409, 0.8423037528991699, 0.847686767578125, 0.853891134262085, 0.8605878949165344, 0.8635885715484619, 0.8673960566520691, 0.8708078265190125, 0.8740268349647522, 0.8771466016769409, 0.880237340927124, 0.8832556009292603, 0.8861218094825745, 0.8889902830123901, 0.8916955590248108, 0.8946933746337891, 0.8971558809280396, 0.8992606997489929, 0.9014995098114014, 0.9032950401306152, 0.9054602980613708, 0.9074651002883911, 0.9091498851776123], 'val_auc': [0.7246610522270203, 0.7795065641403198, 0.8091586828231812, 0.8301818370819092, 0.8450073003768921, 0.8563790321350098, 0.866634726524353, 0.875342607498169, 0.8829135894775391, 0.8897839784622192, 0.8960325121879578, 0.9016290903091431, 0.906787633895874, 0.9113389253616333, 0.9156978130340576, 0.9195630550384521, 0.923202633857727, 0.9266985654830933, 0.929977536201477, 0.9329721927642822, 0.9357746839523315, 0.9383585453033447, 0.94074946641922, 0.9429941177368164, 0.9449720978736877, 0.946962296962738, 0.948704719543457, 0.9503145217895508], 'loss': [0.6093442012829949, 0.4892462663379781, 0.43756103108071875, 0.40293630149774934, 0.3769156584227333, 0.3523970713545551, 0.3254831327405168, 0.3054313944227384, 0.2890101649385669, 0.2694155422831921, 0.25264798277609224, 0.23967224017458813, 0.22484798429213165, 0.2128742086326974, 0.19764868727679363, 0.18633384727878594, 0.17603674248970763, 0.16067208175039116, 0.15059567534879886, 0.14157797014101958, 0.1304080939609489, 0.12187871011258336, 0.11303660757521279, 0.10769358940504409, 0.10247918260221225, 0.09156587429717639, 0.08631854803643675, 0.08672817714594222], 'tp': [197.85715, 683.1429, 1191.5714, 1710.7142, 2241.4285, 2785.1428, 3314.2856, 3849.7144, 4383.5713, 4941.7144, 5494.857, 6039.143, 6587.2856, 7148.2856, 7700.0, 8265.857, 8822.0, 9390.714, 9954.0, 10519.286, 11098.429, 11677.286, 12256.571, 12832.429, 13405.0, 13982.714, 14565.857, 15142.714], 'fp': [85.42857, 218.85715, 337.42856, 442.7143, 546.5714, 635.2857, 733.1429, 817.0, 901.7143, 984.7143, 1061.8572, 1124.8572, 1186.8572, 1244.2858, 1297.0, 1347.0, 1392.7142, 1428.2858, 1461.1428, 1488.2858, 1516.7142, 1542.1428, 1567.5714, 1589.5714, 1610.5714, 1625.7142, 1641.8572, 1660.1428], 'tn': [115.28571, 337.42856, 579.1429, 832.4286, 1088.1428, 1347.4286, 1611.1428, 1886.0, 2167.7144, 2435.2856, 2716.1428, 3008.7144, 3313.0, 3607.5715, 3917.4285, 4217.4287, 4537.0, 4858.2856, 5187.0, 5523.0, 5849.2856, 6180.0, 6507.143, 6842.2856, 7182.2856, 7525.0, 7866.857, 8208.0], 'fn': [102.42857, 225.57143, 320.85715, 407.14285, 480.85715, 553.1429, 626.4286, 696.2857, 760.0, 815.2857, 868.1429, 932.2857, 981.8571, 1032.8572, 1082.5714, 1130.7142, 1173.2858, 1211.7142, 1250.8572, 1286.4286, 1316.5714, 1345.5714, 1377.7142, 1408.7142, 1439.1428, 1467.5714, 1490.4286, 1518.1428], 'accuracy': [0.5965886, 0.6947338, 0.7283911, 0.74920356, 0.76396644, 0.7765573, 0.7835938, 0.79116535, 0.79761845, 0.8038022, 0.80964375, 0.81471646, 0.8202734, 0.82525367, 0.8299705, 0.83436644, 0.83884674, 0.843665, 0.84807366, 0.85252476, 0.85675037, 0.86078537, 0.8643157, 0.8677487, 0.87096554, 0.87425107, 0.8774677, 0.8801875], 'precision': [0.67671883, 0.7570974, 0.77908593, 0.794314, 0.80383766, 0.8142558, 0.81882674, 0.8248927, 0.8293718, 0.8338233, 0.83802545, 0.8429647, 0.84730875, 0.8517256, 0.85582644, 0.8598644, 0.86364, 0.86797065, 0.8719855, 0.87604195, 0.8797584, 0.8833327, 0.8865967, 0.88977426, 0.8927315, 0.895836, 0.89869183, 0.90119267], 'recall': [0.62632066, 0.74913025, 0.7871693, 0.8073884, 0.82313293, 0.83418715, 0.8409611, 0.84676844, 0.8521773, 0.8583234, 0.8635346, 0.8662368, 0.8702587, 0.8737317, 0.8767185, 0.87964934, 0.8826009, 0.88569945, 0.88835204, 0.8910203, 0.8939403, 0.89666593, 0.898943, 0.90107346, 0.9030425, 0.9050056, 0.90716743, 0.90887386], 'auc': [0.6395549, 0.7630316, 0.7991261, 0.82199144, 0.83990395, 0.85375595, 0.8631557, 0.8729766, 0.88106495, 0.8877471, 0.8943747, 0.8999317, 0.905527, 0.91020817, 0.914578, 0.91859454, 0.92233676, 0.92593765, 0.9292647, 0.9323673, 0.9351956, 0.9378848, 0.9402865, 0.9425634, 0.94471633, 0.94660693, 0.94855547, 0.95010024]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmM9UGoDpHUJ",
        "colab_type": "text"
      },
      "source": [
        "Импортируем результаты из задания для сравнения и построения ROC curve, т.к. примем их за истину, как значения y_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDkI1McyJIyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = pd.read_csv('/content/sample_submission.csv')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKpmeTN7ppiG",
        "colab_type": "text"
      },
      "source": [
        "Совершаем предсказания для X_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUXIeSzIin_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test.values)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWzUo0zkpUGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_name = pd.DataFrame(X_name)\n",
        "X_name['y'] = np.nan\n",
        "for i in range(len(X_name)):\n",
        "    X_name['y'][i] = np.around([y_pred[i][0]], decimals = 3)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjY0O3UCpxeK",
        "colab_type": "text"
      },
      "source": [
        "Количество строк в датасете результата из задания и предсказания отличаются. По причине, различия обработки тестовых и тренировочных данных. \n",
        "\n",
        "**P.S.** Если в датасете результата, сохранены все строки, то такого результата можно было бы добиться следующим способом. Удаление солбцов с большим количеством NaN и +-inf, либо замена NaN, как 0 (либо одно число, если в столбце уже имеется 0) и +-inf, как большое число +-float (умещающиеся в памяти). Тем не менее, мне такой подход показался не правильным, т.к. +-inf, подобие +-бесконечности, а как известно бесконечность != бесконечности, по этой причине inf - inf = NaN, т.е. напрашивается второй вывод, NaN != NaN.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfq3kl37rU8V",
        "colab_type": "text"
      },
      "source": [
        "Объеденим результат предсказания с результатом из задания (удалив недостающие строки)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itmw5XPvtaeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = X_name.merge(y_test_d, left_on='sample_id', right_on='sample_id')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_o5Fe1nrgqE",
        "colab_type": "text"
      },
      "source": [
        "Как упоминалось ранее, результат предсказания из задания, считаем как истиный, и по этим данным строим ROC. Для этого округлим значения до результата предсказания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FpN8GQlPNvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(df)):\n",
        "    df['y_y'][i] = np.around([df['y_y'][i]], decimals = 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR4wn_Z6rxzP",
        "colab_type": "text"
      },
      "source": [
        "Построим ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd254_-RKTS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "c13d11fd-527b-4b60-9948-394b0f93e942"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "sns.set(font_scale=1.5)\n",
        "sns.set_color_codes(\"muted\")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "fpr, tpr, thresholds = roc_curve(df['y_y'], model.predict(X_test).ravel(), pos_label=1)\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, lw=lw, label='ROC curve ')\n",
        "plt.plot([0, 1], [0, 1])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC curve')\n",
        "plt.savefig(\"ROC.png\")\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mycMO88rsMEg",
        "colab_type": "text"
      },
      "source": [
        "Сравним отличные значения точек и выведим название образца."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6t3tH48shgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "34134ff1-a47f-472b-e466-7983a79fae80"
      },
      "source": [
        "for i in range(len(df)):\n",
        "    if np.around([df['y_x'][i]], decimals = 0) != df['y_y'][i]:\n",
        "        print(df['sample_id'][i])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_1098\n",
            "sample_1102\n",
            "sample_1150\n",
            "sample_1152\n",
            "sample_1155\n",
            "sample_1163\n",
            "sample_1173\n",
            "sample_1195\n",
            "sample_1240\n",
            "sample_1244\n",
            "sample_1250\n",
            "sample_1266\n",
            "sample_1267\n",
            "sample_1268\n",
            "sample_1277\n",
            "sample_1278\n",
            "sample_1286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv1Sws2Vt7US",
        "colab_type": "text"
      },
      "source": [
        "В процетном соотношении."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4qGhAJht5WH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d209e0e5-494c-48b6-b8c8-5385b233a660"
      },
      "source": [
        "17/164 * 100"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.365853658536585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhKpfOhar2xZ",
        "colab_type": "text"
      },
      "source": [
        "# Сравнение моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRaWr9i4wKiH",
        "colab_type": "text"
      },
      "source": [
        "Без сокращений. Пересрестная проверка. Параметр cv - cross-validated, означает вычисления значений cv раз подряд (каждый раз с разными разбиениями). Возьмем этот параметр равным количеству epoch в keras модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI2SnkOlIe_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.feature_selection import RFECV"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73QogsOMxsfQ",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkByolwpIY51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR = LogisticRegression()\n",
        "\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(LR, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "LR_fit_time = scores['fit_time'].mean()\n",
        "LR_score_time = scores['score_time'].mean()\n",
        "LR_accuracy = scores['test_accuracy'].mean()\n",
        "LR_precision = scores['test_precision_macro'].mean()\n",
        "LR_recall = scores['test_recall_macro'].mean()\n",
        "LR_f1 = scores['test_f1_weighted'].mean()\n",
        "LR_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z49TKXeWxt2W",
        "colab_type": "text"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7CT4cvAIj1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(decision_tree, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "dtree_fit_time = scores['fit_time'].mean()\n",
        "dtree_score_time = scores['score_time'].mean()\n",
        "dtree_accuracy = scores['test_accuracy'].mean()\n",
        "dtree_precision = scores['test_precision_macro'].mean()\n",
        "dtree_recall = scores['test_recall_macro'].mean()\n",
        "dtree_f1 = scores['test_f1_weighted'].mean()\n",
        "dtree_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "calzY48rzG01",
        "colab_type": "text"
      },
      "source": [
        "Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8aJGZrlzJnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVM = SVC(probability = True)\n",
        "\n",
        "scoring = ['accuracy','precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(SVM, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "SVM_fit_time = scores['fit_time'].mean()\n",
        "SVM_score_time = scores['score_time'].mean()\n",
        "SVM_accuracy = scores['test_accuracy'].mean()\n",
        "SVM_precision = scores['test_precision_macro'].mean()\n",
        "SVM_recall = scores['test_recall_macro'].mean()\n",
        "SVM_f1 = scores['test_f1_weighted'].mean()\n",
        "SVM_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CWG6HFAzL_x",
        "colab_type": "text"
      },
      "source": [
        "Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzrK5CyAzPTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LDA = LinearDiscriminantAnalysis()\n",
        "\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(LDA, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "LDA_fit_time = scores['fit_time'].mean()\n",
        "LDA_score_time = scores['score_time'].mean()\n",
        "LDA_accuracy = scores['test_accuracy'].mean()\n",
        "LDA_precision = scores['test_precision_macro'].mean()\n",
        "LDA_recall = scores['test_recall_macro'].mean()\n",
        "LDA_f1 = scores['test_f1_weighted'].mean()\n",
        "LDA_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3vN57ouzS5W",
        "colab_type": "text"
      },
      "source": [
        "Quadratic Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNWjFA23zU4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QDA = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(QDA, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "QDA_fit_time = scores['fit_time'].mean()\n",
        "QDA_score_time = scores['score_time'].mean()\n",
        "QDA_accuracy = scores['test_accuracy'].mean()\n",
        "QDA_precision = scores['test_precision_macro'].mean()\n",
        "QDA_recall = scores['test_recall_macro'].mean()\n",
        "QDA_f1 = scores['test_f1_weighted'].mean()\n",
        "QDA_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MdPIMPGzYgB",
        "colab_type": "text"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9VH325Pzb44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "forest_fit_time = scores['fit_time'].mean()\n",
        "forest_score_time = scores['score_time'].mean()\n",
        "forest_accuracy = scores['test_accuracy'].mean()\n",
        "forest_precision = scores['test_precision_macro'].mean()\n",
        "forest_recall = scores['test_recall_macro'].mean()\n",
        "forest_f1 = scores['test_f1_weighted'].mean()\n",
        "forest_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltr9IDR6zeOI",
        "colab_type": "text"
      },
      "source": [
        "K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdcm0Es8zh8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KNN = KNeighborsClassifier()\n",
        "\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(KNN, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "KNN_fit_time = scores['fit_time'].mean()\n",
        "KNN_score_time = scores['score_time'].mean()\n",
        "KNN_accuracy = scores['test_accuracy'].mean()\n",
        "KNN_precision = scores['test_precision_macro'].mean()\n",
        "KNN_recall = scores['test_recall_macro'].mean()\n",
        "KNN_f1 = scores['test_f1_weighted'].mean()\n",
        "KNN_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYZkk_9pzlOC",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_O78WZbzppq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bayes = GaussianNB()\n",
        "\n",
        "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
        "scores = cross_validate(bayes, X_train, y_train, scoring=scoring, cv=28)\n",
        "\n",
        "sorted(scores.keys())\n",
        "bayes_fit_time = scores['fit_time'].mean()\n",
        "bayes_score_time = scores['score_time'].mean()\n",
        "bayes_accuracy = scores['test_accuracy'].mean()\n",
        "bayes_precision = scores['test_precision_macro'].mean()\n",
        "bayes_recall = scores['test_recall_macro'].mean()\n",
        "bayes_f1 = scores['test_f1_weighted'].mean()\n",
        "bayes_roc = scores['test_roc_auc'].mean()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNSZDAxI1OEI",
        "colab_type": "text"
      },
      "source": [
        "Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPQgfo8z1QB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e5f1ac97-a67b-4039-e743-8002f13a2089"
      },
      "source": [
        "print('\\nhistory dict:', history.history)    # Для оценки AUC и выбора параметров. "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "history dict: {'val_loss': [0.5306934954791234, 0.4908246085561555, 0.4796790961561532, 0.4626501173808657, 0.4529381858891454, 0.49372588211092455, 0.49111901727215995, 0.5116221980801944, 0.49801892083266686, 0.5036941772904889, 0.5384767980411135, 0.5402786633064007, 0.540773147961189, 0.5640846807381202, 0.5683454357344528, 0.5949245736516755, 0.5794739651268926, 0.5863640180949508, 0.5958913747606607, 0.6141998880896075, 0.6280758206186623, 0.6573829644712909, 0.6763245691513193, 0.6588934236559375, 0.7062640210677837, 0.679819944809223, 0.7460975741517955, 0.7227400185733006], 'val_tp': [422.0, 927.0, 1441.5, 1966.0, 2501.0, 3036.5, 3568.0, 4104.5, 4652.0, 5210.0, 5751.5, 6302.5, 6855.0, 7410.0, 7968.0, 8529.5, 9094.0, 9660.5, 10230.5, 10802.0, 11380.5, 11955.5, 12528.5, 13106.0, 13679.5, 14261.0, 14842.5, 15421.0], 'val_fp': [144.0, 274.5, 384.0, 486.0, 588.0, 682.5, 770.0, 854.5, 940.0, 1024.0, 1093.0, 1156.0, 1213.0, 1271.0, 1321.0, 1370.0, 1412.0, 1447.0, 1476.0, 1503.0, 1531.0, 1557.0, 1580.0, 1605.0, 1620.0, 1637.0, 1654.0, 1671.0], 'val_tn': [211.5, 439.0, 687.5, 943.5, 1199.5, 1463.0, 1733.5, 2007.0, 2279.5, 2553.5, 2842.5, 3137.5, 3438.5, 3738.5, 4046.5, 4355.5, 4671.5, 4994.5, 5323.5, 5654.5, 5984.5, 6316.5, 6651.5, 6984.5, 7327.5, 7668.5, 8009.5, 8350.5], 'val_fn': [178.0, 279.0, 370.5, 452.0, 523.0, 593.5, 668.0, 737.5, 796.0, 844.0, 908.5, 963.5, 1017.0, 1068.0, 1116.0, 1160.5, 1202.0, 1241.5, 1277.5, 1312.0, 1339.5, 1370.5, 1403.5, 1432.0, 1464.5, 1489.0, 1513.5, 1541.0], 'val_accuracy': [0.6629956364631653, 0.7116414308547974, 0.7383370399475098, 0.7562041282653809, 0.7690941691398621, 0.7790665626525879, 0.7866307497024536, 0.7933405637741089, 0.7997114658355713, 0.8060529828071594, 0.8110990524291992, 0.8166443109512329, 0.8219347596168518, 0.8265801668167114, 0.8313669562339783, 0.835847020149231, 0.8404102325439453, 0.8449851274490356, 0.849597156047821, 0.8539294004440308, 0.8581453561782837, 0.8619071245193481, 0.8653867840766907, 0.8686844706535339, 0.8719673156738281, 0.875236988067627, 0.8782643675804138, 0.8809642791748047], 'val_precision': [0.7455731630325317, 0.7715326547622681, 0.7896447777748108, 0.8017932772636414, 0.8096464276313782, 0.816482663154602, 0.8224985003471375, 0.8276869058609009, 0.8319026827812195, 0.8357394933700562, 0.840309739112854, 0.8450090885162354, 0.8496529459953308, 0.8535882830619812, 0.8577888011932373, 0.8616092205047607, 0.8656005859375, 0.8697276711463928, 0.8739162087440491, 0.877854585647583, 0.8814235329627991, 0.8847733736038208, 0.8880107402801514, 0.8908979892730713, 0.8941141963005066, 0.8970310688018799, 0.8997362852096558, 0.9022349715232849], 'val_recall': [0.7033203840255737, 0.7686551213264465, 0.7955284714698792, 0.8130674958229065, 0.8270496129989624, 0.8365011811256409, 0.8423037528991699, 0.847686767578125, 0.853891134262085, 0.8605878949165344, 0.8635885715484619, 0.8673960566520691, 0.8708078265190125, 0.8740268349647522, 0.8771466016769409, 0.880237340927124, 0.8832556009292603, 0.8861218094825745, 0.8889902830123901, 0.8916955590248108, 0.8946933746337891, 0.8971558809280396, 0.8992606997489929, 0.9014995098114014, 0.9032950401306152, 0.9054602980613708, 0.9074651002883911, 0.9091498851776123], 'val_auc': [0.7246610522270203, 0.7795065641403198, 0.8091586828231812, 0.8301818370819092, 0.8450073003768921, 0.8563790321350098, 0.866634726524353, 0.875342607498169, 0.8829135894775391, 0.8897839784622192, 0.8960325121879578, 0.9016290903091431, 0.906787633895874, 0.9113389253616333, 0.9156978130340576, 0.9195630550384521, 0.923202633857727, 0.9266985654830933, 0.929977536201477, 0.9329721927642822, 0.9357746839523315, 0.9383585453033447, 0.94074946641922, 0.9429941177368164, 0.9449720978736877, 0.946962296962738, 0.948704719543457, 0.9503145217895508], 'loss': [0.6093442012829949, 0.4892462663379781, 0.43756103108071875, 0.40293630149774934, 0.3769156584227333, 0.3523970713545551, 0.3254831327405168, 0.3054313944227384, 0.2890101649385669, 0.2694155422831921, 0.25264798277609224, 0.23967224017458813, 0.22484798429213165, 0.2128742086326974, 0.19764868727679363, 0.18633384727878594, 0.17603674248970763, 0.16067208175039116, 0.15059567534879886, 0.14157797014101958, 0.1304080939609489, 0.12187871011258336, 0.11303660757521279, 0.10769358940504409, 0.10247918260221225, 0.09156587429717639, 0.08631854803643675, 0.08672817714594222], 'tp': [197.85715, 683.1429, 1191.5714, 1710.7142, 2241.4285, 2785.1428, 3314.2856, 3849.7144, 4383.5713, 4941.7144, 5494.857, 6039.143, 6587.2856, 7148.2856, 7700.0, 8265.857, 8822.0, 9390.714, 9954.0, 10519.286, 11098.429, 11677.286, 12256.571, 12832.429, 13405.0, 13982.714, 14565.857, 15142.714], 'fp': [85.42857, 218.85715, 337.42856, 442.7143, 546.5714, 635.2857, 733.1429, 817.0, 901.7143, 984.7143, 1061.8572, 1124.8572, 1186.8572, 1244.2858, 1297.0, 1347.0, 1392.7142, 1428.2858, 1461.1428, 1488.2858, 1516.7142, 1542.1428, 1567.5714, 1589.5714, 1610.5714, 1625.7142, 1641.8572, 1660.1428], 'tn': [115.28571, 337.42856, 579.1429, 832.4286, 1088.1428, 1347.4286, 1611.1428, 1886.0, 2167.7144, 2435.2856, 2716.1428, 3008.7144, 3313.0, 3607.5715, 3917.4285, 4217.4287, 4537.0, 4858.2856, 5187.0, 5523.0, 5849.2856, 6180.0, 6507.143, 6842.2856, 7182.2856, 7525.0, 7866.857, 8208.0], 'fn': [102.42857, 225.57143, 320.85715, 407.14285, 480.85715, 553.1429, 626.4286, 696.2857, 760.0, 815.2857, 868.1429, 932.2857, 981.8571, 1032.8572, 1082.5714, 1130.7142, 1173.2858, 1211.7142, 1250.8572, 1286.4286, 1316.5714, 1345.5714, 1377.7142, 1408.7142, 1439.1428, 1467.5714, 1490.4286, 1518.1428], 'accuracy': [0.5965886, 0.6947338, 0.7283911, 0.74920356, 0.76396644, 0.7765573, 0.7835938, 0.79116535, 0.79761845, 0.8038022, 0.80964375, 0.81471646, 0.8202734, 0.82525367, 0.8299705, 0.83436644, 0.83884674, 0.843665, 0.84807366, 0.85252476, 0.85675037, 0.86078537, 0.8643157, 0.8677487, 0.87096554, 0.87425107, 0.8774677, 0.8801875], 'precision': [0.67671883, 0.7570974, 0.77908593, 0.794314, 0.80383766, 0.8142558, 0.81882674, 0.8248927, 0.8293718, 0.8338233, 0.83802545, 0.8429647, 0.84730875, 0.8517256, 0.85582644, 0.8598644, 0.86364, 0.86797065, 0.8719855, 0.87604195, 0.8797584, 0.8833327, 0.8865967, 0.88977426, 0.8927315, 0.895836, 0.89869183, 0.90119267], 'recall': [0.62632066, 0.74913025, 0.7871693, 0.8073884, 0.82313293, 0.83418715, 0.8409611, 0.84676844, 0.8521773, 0.8583234, 0.8635346, 0.8662368, 0.8702587, 0.8737317, 0.8767185, 0.87964934, 0.8826009, 0.88569945, 0.88835204, 0.8910203, 0.8939403, 0.89666593, 0.898943, 0.90107346, 0.9030425, 0.9050056, 0.90716743, 0.90887386], 'auc': [0.6395549, 0.7630316, 0.7991261, 0.82199144, 0.83990395, 0.85375595, 0.8631557, 0.8729766, 0.88106495, 0.8877471, 0.8943747, 0.8999317, 0.905527, 0.91020817, 0.914578, 0.91859454, 0.92233676, 0.92593765, 0.9292647, 0.9323673, 0.9351956, 0.9378848, 0.9402865, 0.9425634, 0.94471633, 0.94660693, 0.94855547, 0.95010024]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjdikW3e1ZSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Keras_AUC = 0.95010024\n",
        "Keras_recall = 0.90887386\n",
        "Keras_precision = 0.90119267\n",
        "Keras_accuracy = 0.8801875\n",
        "Keras_f1 = 2*(Keras_recall*Keras_precision)/(Keras_precision+Keras_recall)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFgIGa0I17VB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9757394a-4683-41df-d3cd-99b3431f601f"
      },
      "source": [
        "Keras_recall = 0.90887386\n",
        "Keras_precision = 0.90119267\n",
        "2*(Keras_recall*Keras_precision)/(Keras_precision+Keras_recall)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9050169670687256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm0utu4ezu3S",
        "colab_type": "text"
      },
      "source": [
        "**Сравниваем модели.** По результатам сравнения, наша keras модель на порядок лучше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_oZbOzqzwyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "127e4955-6159-4453-cdad-9917eb7c2d70"
      },
      "source": [
        "models_initial = pd.DataFrame({\n",
        "    'Model'       : ['Keras Model','Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes'],\n",
        "    'Accuracy'    : [Keras_accuracy,LR_accuracy, dtree_accuracy, SVM_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy],\n",
        "    'Precision'   : [Keras_precision,LR_precision, dtree_precision, SVM_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision],\n",
        "    'Recall'      : [Keras_recall,LR_recall, dtree_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall],\n",
        "    'F1_score'    : [Keras_f1,LR_f1, dtree_f1, SVM_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1],\n",
        "    'AUC_ROC'     : [Keras_AUC,LR_roc, dtree_roc, SVM_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc],\n",
        "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
        "\n",
        "models_initial.sort_values(by='Accuracy', ascending=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_score</th>\n",
              "      <th>AUC_ROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keras Model</td>\n",
              "      <td>0.880188</td>\n",
              "      <td>0.901193</td>\n",
              "      <td>0.908874</td>\n",
              "      <td>0.905017</td>\n",
              "      <td>0.950100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>0.780012</td>\n",
              "      <td>0.789262</td>\n",
              "      <td>0.736282</td>\n",
              "      <td>0.767379</td>\n",
              "      <td>0.848159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.779112</td>\n",
              "      <td>0.776108</td>\n",
              "      <td>0.749515</td>\n",
              "      <td>0.773397</td>\n",
              "      <td>0.845877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>K-Nearest Neighbors</td>\n",
              "      <td>0.761375</td>\n",
              "      <td>0.764573</td>\n",
              "      <td>0.714060</td>\n",
              "      <td>0.747316</td>\n",
              "      <td>0.802578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.739826</td>\n",
              "      <td>0.727132</td>\n",
              "      <td>0.716817</td>\n",
              "      <td>0.736670</td>\n",
              "      <td>0.795150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.719988</td>\n",
              "      <td>0.704186</td>\n",
              "      <td>0.700179</td>\n",
              "      <td>0.718827</td>\n",
              "      <td>0.700179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.707833</td>\n",
              "      <td>0.692304</td>\n",
              "      <td>0.660334</td>\n",
              "      <td>0.692830</td>\n",
              "      <td>0.696494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bayes</td>\n",
              "      <td>0.679382</td>\n",
              "      <td>0.679090</td>\n",
              "      <td>0.681601</td>\n",
              "      <td>0.680640</td>\n",
              "      <td>0.753958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.580942</td>\n",
              "      <td>0.569275</td>\n",
              "      <td>0.569680</td>\n",
              "      <td>0.582954</td>\n",
              "      <td>0.565768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Model  Accuracy  ...  F1_score   AUC_ROC\n",
              "0                      Keras Model  0.880188  ...  0.905017  0.950100\n",
              "3           Support Vector Machine  0.780012  ...  0.767379  0.848159\n",
              "6                    Random Forest  0.779112  ...  0.773397  0.845877\n",
              "7              K-Nearest Neighbors  0.761375  ...  0.747316  0.802578\n",
              "1              Logistic Regression  0.739826  ...  0.736670  0.795150\n",
              "2                    Decision Tree  0.719988  ...  0.718827  0.700179\n",
              "5  Quadratic Discriminant Analysis  0.707833  ...  0.692830  0.696494\n",
              "8                            Bayes  0.679382  ...  0.680640  0.753958\n",
              "4     Linear Discriminant Analysis  0.580942  ...  0.582954  0.565768\n",
              "\n",
              "[9 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}